{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citibike Stations' Inflow/Outflow Ratio\n",
    "Group Members:\n",
    "Cindy Y. Liu, Yuxiang Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Load Default settings\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Citibike data\n",
    "df = pd.read_csv('201508-citibike-tripdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary features\n",
    "df = df.drop(['tripduration','starttime','stoptime'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the information of stations into a csv file which includes longitude,latitude and station id\n",
    "start = pd.DataFrame({'ID': df['start station id'], \\\n",
    "                    'Latitude': df['start station latitude'],\\\n",
    "                    'Longitude':df['start station longitude']})\n",
    "end = pd.DataFrame({'ID': df['end station id'], \\\n",
    "                    'Latitude': df['end station latitude'],\\\n",
    "                    'Longitude':df['end station longitude']})\n",
    "merged = pd.concat([start,end],axis=0)\n",
    "merged = merged.drop_duplicates('ID')\n",
    "merged.to_csv('station.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Geopy package to [reverse geocoding](https://en.wikipedia.org/wiki/Reverse_geocoding) by converting geographic coordinates (latitude and longitude) into street addresses. Based on these, we get the corresponding borough information for each Citibike station and store the information into a csv file named 'stationbyborough'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "stations = pd.read_csv('station.csv')\n",
    "output = np.empty(len(stations), dtype='object')\n",
    "for index,station in stations.iterrows():\n",
    "    geolocator = Nominatim()\n",
    "    location = geolocator.reverse(\"%s,%s\"%(str(station['Latitude']), str(station['Longitude'])),timeout=10)\n",
    "    if location.raw[\"address\"][\"county\"]==\"New York County\"or location.raw[\"address\"][\"county\"]==\"New York\":\n",
    "        output[index]=\"Manhattan\"\n",
    "    else:\n",
    "        if location.raw[\"address\"][\"county\"]==\"Kings County\":\n",
    "            output[index]=\"Brooklyn\"\n",
    "        else:\n",
    "            if location.raw[\"address\"][\"county\"]==\"Queens County\":\n",
    "                output[index]=\"Queens\"\n",
    "            else:\n",
    "                output[index]=location.raw[\"address\"][\"county\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we store the information into a csv file named 'stationbyborough'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.tofile('stationbyborough.csv',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load stations by borough csv file\n",
    "stations_by_borough = pd.read_csv('stationbyborough.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty arrays for storing the number of inflow trips, outflow trips, and the ratio of inflow trips to total trips for each citibike station\n",
    "in_jour, out_jour, in_out_ratio = np.zeros(len(stations_by_borough)),np.zeros(len(stations_by_borough)),np.zeros(len(stations_by_borough))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e59a06f7d2df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Iterate through all the stations to get the total number of inflow and outflow trips of each station\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstations_by_borough\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start station id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end station id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0min_jour\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   1607\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1609\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1610\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# Iterate through all the stations to get the total number of inflow and outflow trips of each station\n",
    "for index, station in stations_by_borough.iterrows():\n",
    "    start = sum(df['start station id']==station['id'])\n",
    "    end = sum(df['end station id']==station['id'])\n",
    "    in_jour[index]= start\n",
    "    out_jour[index]= end\n",
    "    in_out_ratio[index] = start/float(end+start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new data frame which includes all the inflow and outflow information of each station\n",
    "results = pd.DataFrame({'sid':stations_by_borough['id'],\\\n",
    "                      'inflow':in_jour,\\\n",
    "                      'outflow':out_jour,\\\n",
    "                      'ratio':in_out_ratio,\\\n",
    "                      'borough':stations_by_borough['BoroName']})\n",
    "cols = ['sid','inflow','outflow','ratio','borough']\n",
    "results = results[cols]\n",
    "results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the summary statistics for the new data frame\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the number of both Manhattan and Brooklyn stations\n",
    "pd.value_counts(results['borough'].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new dataframes for Manhattan and Brooklyn seperately\n",
    "manhattan = results[results['borough']=='Manhattan']\n",
    "brooklyn = results[results['borough']=='Brooklyn']\n",
    "\n",
    "norm_m = 1\n",
    "norm_b = 1\n",
    "\n",
    "error_m = np.sqrt(manhattan['ratio'].count())\n",
    "error_b = np.sqrt(brooklyn['ratio'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create histograms for Manhattan and Brooklyn's inflow to outflow trips ratio\n",
    "fig = pl.figure(figsize(10,10))\n",
    "gs = gridspec.GridSpec(2, 1)\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "manhattan['ratio'].plot(kind=\"hist\",yerr=[((error_m)/norm_m,(error_m)/norm_m)],\\\n",
    "                        bins=30,color='IndianRed', alpha=0.5,normed=1)\n",
    "ax.set_title('Manhattan Stations')\n",
    "bx = fig.add_subplot(gs[1,0])\n",
    "brooklyn['ratio'].plot(kind=\"hist\",yerr=[((error_b)/norm_b,(error_b)/norm_b)],\\\n",
    "                       bins=30, alpha=0.5,normed=1)\n",
    "bx.set_title('Brooklyn Stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display summary statitics for Manhattan and Brooklyn's inflow to outflow trips ratio\n",
    "manhattan['ratio'].describe()\n",
    "brooklyn['ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis: \n",
    "Manhattan's citibike stations have less inflow trips than Brooklyn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z test for the mean of inflow to total trips ratios for two samples\n",
    "\n",
    "$H_{0} : p_m-p_b>0$\n",
    "\n",
    "$H_{\\alpha}: p_m-p_b<=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation for two samples\n",
    "mean_m = np.mean(manhattan['ratio'])\n",
    "mean_b = np.mean(brooklyn['ratio'])\n",
    "std_m = np.std(manhattan['ratio'])\n",
    "std_b = np.std(brooklyn['ratio'])\n",
    "n_m = len(manhattan)\n",
    "n_b = len(brooklyn)\n",
    "\n",
    "# Create formula to calculate the standard error for the difference\n",
    "SE = lambda sd1,sd2,n1,n2: np.sqrt(sd1**2/float(n1)+sd2**2/float(n2))\n",
    "se = SE(std_m, std_b, n_m, n_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the two sample z-test to evaluate the difference between two groups\n",
    "z_1 = (mean_m - mean_b)/se\n",
    "print z_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# According to the Z-score to, compute the p-value and compare against the critical value.\n",
    "p_1 = 0.5319\n",
    "alpha = 0.05\n",
    "def report_result(p,a):\n",
    "    print 'Is the p value {0:.2f} smaller than the critical value {1:.2f}? '.format(p,a)\n",
    "\n",
    "    print '{0}, the Null hypothesis is {1}'.format( 'Yes' if p<a  else 'No','rejected'if p<a else'not rejected')\n",
    "\n",
    "    \n",
    "report_result(p_1,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z test for the proportion of trips which have more inflow trips than outflow trips (ratio > 0.5) to the total trips  in two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_0 = sum(manhattan['ratio']>=0.5)/float(len(manhattan))\n",
    "P_1 = sum(brooklyn['ratio']>=0.5)/float(len(brooklyn))\n",
    "\n",
    "n_0 = len(manhattan)\n",
    "n_1 = len(brooklyn)\n",
    "\n",
    "Nt_0 = P_0*n_0\n",
    "Nt_1 = P_1*n_1\n",
    "print (P_0, P_1, n_0, n_1)\n",
    "\n",
    "# Pooled Sample Proportion\n",
    "psp =(P_0*n_0+P_1*n_1)/(n_1+n_0)\n",
    "\n",
    "SE = lambda p, n1, n2: np.sqrt(psp*(1-psp)*(1/float(n1)+1/float(n2)))\n",
    "\n",
    "se = SE(P_0,n_0,n_1)\n",
    "\n",
    "# Z-score\n",
    "zscore = lambda p0, p1, s : (p0-p1)/s\n",
    "z_2 = zscore(P_1, P_0, se)\n",
    "print(z_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 1 - 0.6179\n",
    "alpha = 0.05\n",
    "def report_result(p,a):\n",
    "    print 'Is the p value {0:.2f} smaller than the critical value {1:.2f}? '.format(p,a)\n",
    "   \n",
    "    print '{0}, the Null hypothesis is {1}'.format( 'Yes' if p<a  else 'No','rejected'if p<a else'not rejected')\n",
    "\n",
    "report_result(p,alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
